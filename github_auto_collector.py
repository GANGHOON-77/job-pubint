# -*- coding: utf-8 -*-
"""
GitHub Actionsìš© ìë™ ìˆ˜ì§‘ ë° ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸
- 5ë¶„ë§ˆë‹¤ ì‹ ê·œ ê²Œì‹œê¸€ ì²´í¬ ë° ìˆ˜ì§‘
- 30ì¼ ì§€ë‚œ ê²Œì‹œê¸€ ìë™ ì‚­ì œ
"""

import os
import sys
import json
import requests
from datetime import datetime, timedelta
import firebase_admin
from firebase_admin import credentials, firestore
from bs4 import BeautifulSoup
import time

class GitHubAutoCollector:
    def __init__(self):
        self.service_key = os.getenv('SERVICE_KEY')
        self.firebase_key_path = 'firebase-key.json'
        self.db = None
        self.existing_job_ids = set()
        
        if not self.service_key:
            raise ValueError("SERVICE_KEY environment variable not set")
            
        self.init_firebase()
        self.load_existing_jobs()
        
    def init_firebase(self):
        """Firebase ì´ˆê¸°í™”"""
        try:
            if not firebase_admin._apps:
                cred = credentials.Certificate(self.firebase_key_path)
                firebase_admin.initialize_app(cred)
            
            self.db = firestore.client()
            print("âœ… Firebase ì—°ê²° ì„±ê³µ")
            
        except Exception as e:
            print(f"âŒ Firebase ì—°ê²° ì‹¤íŒ¨: {e}")
            sys.exit(1)
            
    def load_existing_jobs(self):
        """ê¸°ì¡´ ì±„ìš©ê³µê³  ID ë¡œë“œ"""
        try:
            docs = self.db.collection('recruitment_jobs').stream()
            self.existing_job_ids = {doc.to_dict().get('idx') for doc in docs if doc.to_dict().get('idx')}
            print(f"ğŸ“‹ ê¸°ì¡´ ë°ì´í„° {len(self.existing_job_ids)}ê±´ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.existing_job_ids = set()
            
    def delete_old_jobs(self):
        """30ì¼ ì§€ë‚œ ì±„ìš©ê³µê³  ì‚­ì œ"""
        try:
            cutoff_date = datetime.now() - timedelta(days=30)
            cutoff_str = cutoff_date.strftime('%Y-%m-%d')
            
            print(f"ğŸ—‘ï¸ {cutoff_str} ì´ì „ ê³µê³  ì‚­ì œ ì‹œì‘...")
            
            # 30ì¼ ì´ì „ ê³µê³  ì¡°íšŒ
            docs = self.db.collection('recruitment_jobs')\
                         .where('reg_date', '<', cutoff_str)\
                         .stream()
            
            deleted_count = 0
            batch = self.db.batch()
            batch_count = 0
            
            for doc in docs:
                batch.delete(doc.reference)
                batch_count += 1
                deleted_count += 1
                
                # 500ê°œì”© ë°°ì¹˜ë¡œ ì‚­ì œ (Firestore ì œí•œ)
                if batch_count >= 500:
                    batch.commit()
                    batch = self.db.batch()
                    batch_count = 0
                    
            # ë§ˆì§€ë§‰ ë°°ì¹˜ ì»¤ë°‹
            if batch_count > 0:
                batch.commit()
                
            print(f"âœ… ë§Œë£Œëœ ê³µê³  {deleted_count}ê±´ ì‚­ì œ ì™„ë£Œ")
            return deleted_count
            
        except Exception as e:
            print(f"âŒ êµ¬ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
            return 0
            
    def fetch_jobs_from_api(self, page=1, max_pages=3):
        """APIì—ì„œ ì±„ìš©ê³µê³  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            url = "http://apis.data.go.kr/1051000/recruitment/list"
            params = {
                'serviceKey': self.service_key,
                'numOfRows': 100,
                'pageNo': page,
                'returnType': 'JSON'
            }
            
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            
            # API ì‘ë‹µ êµ¬ì¡° í™•ì¸
            if 'result' in data and data['result']:
                return data['result']
            elif 'response' in data and 'body' in data['response'] and 'items' in data['response']['body']:
                return data['response']['body']['items']
            else:
                print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ API ì‘ë‹µ êµ¬ì¡°: {list(data.keys())}")
                return []
                
        except Exception as e:
            print(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨ (í˜ì´ì§€ {page}): {e}")
            return []
            
    def get_job_attachments(self, job_idx):
        """ì±„ìš©ê³µê³  ì²¨ë¶€íŒŒì¼ ì •ë³´ í¬ë¡¤ë§"""
        if not job_idx:
            return {}
            
        try:
            detail_url = f"https://job.alio.go.kr/recruitview.do?idx={job_idx}"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(detail_url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            attachments = {
                'announcement': None,
                'application': None, 
                'job_description': None,
                'others': [],
                'unavailable_reason': None
            }
            
            # ì²¨ë¶€íŒŒì¼ í…Œì´ë¸” ì°¾ê¸°
            tables = soup.find_all('table')
            for table in tables:
                if 'ì²¨ë¶€íŒŒì¼' in table.get_text() or 'ê³µê³ ë¬¸' in table.get_text():
                    rows = table.find_all('tr')
                    
                    for row in rows:
                        cells = row.find_all(['td', 'th'])
                        if len(cells) >= 2:
                            category_cell = cells[0]
                            file_cell = cells[1]
                            
                            category = category_cell.get_text(strip=True)
                            file_link = file_cell.find('a')
                            
                            if file_link:
                                href = file_link.get('href', '')
                                file_name = file_link.get_text(strip=True)
                                
                                if 'fileNo=' in href:
                                    file_id = self.extract_file_id(href)
                                    
                                    if 'ê³µê³ ë¬¸' in category:
                                        attachments['announcement'] = {
                                            'fileID': file_id,
                                            'name': file_name,
                                            'type': 'A'
                                        }
                                    elif 'ì…ì‚¬ì§€ì›ì„œ' in category:
                                        attachments['application'] = {
                                            'fileID': file_id,
                                            'name': file_name,
                                            'type': 'B'
                                        }
                                    elif 'ì§ë¬´ê¸°ìˆ ì„œ' in category:
                                        attachments['job_description'] = {
                                            'fileID': file_id,
                                            'name': file_name,
                                            'type': 'C'
                                        }
                                    elif 'ê¸°íƒ€' in category:
                                        attachments['others'].append({
                                            'fileID': file_id,
                                            'name': file_name,
                                            'type': 'Z'
                                        })
                            elif 'ë¯¸ì²¨ë¶€ì‚¬ìœ ' in category and len(cells) >= 2:
                                reason = file_cell.get_text(strip=True)
                                if reason:
                                    attachments['unavailable_reason'] = reason
                    break
            
            return attachments
            
        except Exception as e:
            print(f"âš ï¸ ì²¨ë¶€íŒŒì¼ í¬ë¡¤ë§ ì‹¤íŒ¨ (idx: {job_idx}): {e}")
            return {}
            
    def extract_file_id(self, url):
        """URLì—ì„œ fileID ë˜ëŠ” fileNo ì¶”ì¶œ"""
        try:
            if 'fileNo=' in url:
                start = url.find('fileNo=') + 7
                end = url.find('&', start)
                if end == -1:
                    return url[start:]
                return url[start:end]
            elif 'fileID=' in url:
                start = url.find('fileID=') + 7
                end = url.find('&', start)
                if end == -1:
                    return url[start:]
                return url[start:end]
        except:
            pass
        return None
        
    def process_job_data(self, job):
        """ì±„ìš©ê³µê³  ë°ì´í„° ì²˜ë¦¬"""
        try:
            # í•„ìˆ˜ í•„ë“œ ì¶”ì¶œ
            job_data = {
                'idx': str(job.get('recrutPblntSn', '')),
                'title': job.get('recrutPbancTtl', ''),
                'dept_name': job.get('instNm', ''),
                'work_region': job.get('workRgnNmLst', ''),
                'employment_type': job.get('empmnStleNmLst', ''),
                'reg_date': self.parse_date(job.get('recrutPblntYmd')),
                'end_date': self.parse_date(job.get('recrutCloseYmd')),
                'recruit_num': self.parse_number(job.get('recrutNope')),
                'recruit_type': job.get('ncsCdNmLst', ''),
                'detail_content': job.get('dtyCn', ''),
                'education': job.get('acdmcrNm', ''),
                'work_field': job.get('ncsCdNmLst', ''),
                'salary_info': job.get('cprtnTypeCd', 'Company policy'),
                'preference': job.get('prefStleNm', ''),
                'recruit_period': f"{self.parse_date(job.get('recrutPblntYmd'))} ~ {self.parse_date(job.get('recrutCloseYmd'))}",
                'src_url': job.get('recrutPbancUrl', ''),
                'source': 'moef_api',
                'status': 'active',
                'created_at': firestore.SERVER_TIMESTAMP,
                'updated_at': firestore.SERVER_TIMESTAMP
            }
            
            return job_data
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
            
    def parse_date(self, date_str):
        """ë‚ ì§œ íŒŒì‹±"""
        if not date_str:
            return None
            
        try:
            date_str = str(date_str).strip()
            
            if re.match(r'\d{4}-\d{2}-\d{2}', date_str):
                return date_str[:10]
            elif re.match(r'\d{8}', date_str):
                return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
            else:
                return datetime.now().strftime('%Y-%m-%d')
                
        except Exception:
            return datetime.now().strftime('%Y-%m-%d')
            
    def parse_number(self, num_str):
        """ìˆ«ì íŒŒì‹±"""
        try:
            import re
            return int(re.sub(r'[^\d]', '', str(num_str))) if num_str else 1
        except:
            return 1
            
    def collect_new_jobs(self):
        """ì‹ ê·œ ì±„ìš©ê³µê³  ìˆ˜ì§‘"""
        print("ğŸ” ì‹ ê·œ ì±„ìš©ê³µê³  ê²€ìƒ‰ ì‹œì‘...")
        
        new_jobs = []
        total_processed = 0
        
        # ìµœê·¼ 3í˜ì´ì§€ë§Œ ì²´í¬ (ì‹ ê·œ ê²Œì‹œê¸€ ìœ„ì£¼)
        for page in range(1, 4):
            print(f"ğŸ“„ í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘...")
            
            jobs = self.fetch_jobs_from_api(page)
            if not jobs:
                continue
                
            for job in jobs:
                total_processed += 1
                job_idx = str(job.get('recrutPblntSn', ''))
                
                if not job_idx or job_idx in self.existing_job_ids:
                    continue
                    
                # ì‹ ê·œ ë°ì´í„° ì²˜ë¦¬
                job_data = self.process_job_data(job)
                if job_data:
                    # ì²¨ë¶€íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
                    print(f"ğŸ“ ì²¨ë¶€íŒŒì¼ ìˆ˜ì§‘ ì¤‘: {job_idx}")
                    attachments = self.get_job_attachments(job_idx)
                    if attachments:
                        job_data['attachments'] = attachments
                    
                    new_jobs.append(job_data)
                    self.existing_job_ids.add(job_idx)
                    
                    time.sleep(1)  # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
                    
        print(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼: ì „ì²´ {total_processed}ê±´ ì¤‘ ì‹ ê·œ {len(new_jobs)}ê±´ ë°œê²¬")
        
        # Firebaseì— ì €ì¥
        if new_jobs:
            self.save_jobs_to_firebase(new_jobs)
            
        return len(new_jobs)
        
    def save_jobs_to_firebase(self, jobs):
        """Firebaseì— ì±„ìš©ê³µê³  ì €ì¥"""
        try:
            batch = self.db.batch()
            
            for job in jobs:
                doc_ref = self.db.collection('recruitment_jobs').document(job['idx'])
                batch.set(doc_ref, job)
                
            batch.commit()
            print(f"âœ… Firebaseì— {len(jobs)}ê±´ ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ Firebase ì €ì¥ ì‹¤íŒ¨: {e}")
            
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        try:
            print("ğŸš€ GitHub Actions ìë™ ìˆ˜ì§‘ ì‹œì‘")
            print(f"â° ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
            # ë§¤ì¼ 3ì‹œì—ë§Œ êµ¬ ë°ì´í„° ì‚­ì œ (GitHub Actions cron ê¸°ì¤€)
            current_hour = datetime.now().hour
            if current_hour == 3:
                deleted_count = self.delete_old_jobs()
                print(f"ğŸ—‘ï¸ êµ¬ ë°ì´í„° ì‚­ì œ: {deleted_count}ê±´")
            
            # ì‹ ê·œ ë°ì´í„° ìˆ˜ì§‘
            new_count = self.collect_new_jobs()
            
            print(f"âœ… ìë™ ìˆ˜ì§‘ ì™„ë£Œ: ì‹ ê·œ {new_count}ê±´")
            
            # ê²°ê³¼ ìš”ì•½
            print("\nğŸ“Š ì‹¤í–‰ ê²°ê³¼ ìš”ì•½:")
            print(f"  - ê¸°ì¡´ ë°ì´í„°: {len(self.existing_job_ids)}ê±´")
            print(f"  - ì‹ ê·œ ìˆ˜ì§‘: {new_count}ê±´") 
            print(f"  - ì‹¤í–‰ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
        except Exception as e:
            print(f"âŒ ìë™ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            sys.exit(1)

if __name__ == "__main__":
    import re
    collector = GitHubAutoCollector()
    collector.run()